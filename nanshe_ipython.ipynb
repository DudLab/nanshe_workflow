{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Test setup. Ignore warnings during production runs.\n",
        "\n",
        "%run ./setup_tests.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Specify input data\n",
        "\n",
        "* `data_dir` (`str`): Where the data is located. (change if data is not in the current directory, normally is)\n",
        "* `data` (`str`): HDF5 file to use as input data.\n",
        "* `dataset` (`str`): HDF5 dataset to use as input data.\n",
        "\n",
        "</br>\n",
        "* `num_workers` (`int`): Number of workers for iPython Cluster. (default all cores excepting one for client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_dir = \"\"\n",
        "data = \"reg.h5\"\n",
        "dataset = \"images\"\n",
        "\n",
        "num_workers = None\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "data_dir = os.path.abspath(data_dir)\n",
        "\n",
        "data_sub = \"_sub\".join(os.path.splitext(data))\n",
        "data_f_f0 = \"_f_f0\".join(os.path.splitext(data))\n",
        "data_wt = \"_wt\".join(os.path.splitext(data))\n",
        "data_norm = \"_norm\".join(os.path.splitext(data))\n",
        "data_dict = \"_dict\".join(os.path.splitext(data))\n",
        "data_post = \"_post\".join(os.path.splitext(data))\n",
        "data_rois = \"_rois\".join(os.path.splitext(data))\n",
        "data_traces = \"_traces\".join(os.path.splitext(data))\n",
        "\n",
        "data_proj = \"_proj\".join(os.path.splitext(data))\n",
        "data_proj_html = os.path.splitext(data_proj)[0] + os.path.extsep + \"html\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configure and startup Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nanshe_workflow.par import cleanup_cluster_files, get_client, set_num_workers\n",
        "\n",
        "num_workers = set_num_workers(num_workers)\n",
        "\n",
        "cleanup_cluster_files(\"sge\")\n",
        "\n",
        "from sys import executable as PYTHON\n",
        "!$PYTHON -m ipyparallel.apps.ipclusterapp start --daemon --profile=sge\n",
        "del PYTHON\n",
        "\n",
        "client = get_client(\"sge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "os.chdir(data_dir)\n",
        "client[:].apply(os.chdir, os.getcwd()).get();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define functions for computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mplview.core import MatplotlibViewer as MPLViewer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "client[:].use_cloudpickle().get()\n",
        "\n",
        "with client[:].sync_imports():\n",
        "    import collections\n",
        "    import contextlib\n",
        "    import copy\n",
        "    import functools\n",
        "    import gc\n",
        "    import inspect\n",
        "    import itertools\n",
        "    import logging\n",
        "    import math\n",
        "    import numbers\n",
        "    import os\n",
        "    import sys\n",
        "\n",
        "    from contextlib import contextmanager\n",
        "\n",
        "    from builtins import range\n",
        "\n",
        "    import numpy\n",
        "    import scipy\n",
        "    import scipy.ndimage\n",
        "    import h5py\n",
        "\n",
        "    import numpy as np\n",
        "    import scipy as sp\n",
        "    import scipy.ndimage as spim\n",
        "    import h5py as hp\n",
        "\n",
        "    from toolz import sliding_window\n",
        "\n",
        "    import imgroi\n",
        "    import imgroi.core\n",
        "    from imgroi.core import label_mask_stack\n",
        "\n",
        "    import nanshe\n",
        "    from nanshe.imp.segment import extract_f0, normalize_data, generate_dictionary\n",
        "    from nanshe.imp.filters.wavelet import transform as wavelet_transform\n",
        "\n",
        "    import nanshe_workflow\n",
        "    from nanshe_workflow.data import DataBlocks, LazyDataset\n",
        "\n",
        "logging.getLogger(\"nanshe\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nanshe_workflow.par import halo_block_parallel\n",
        "\n",
        "from nanshe_workflow.imp import extract_f0_halo\n",
        "from nanshe_workflow.imp import wavelet_transform_halo\n",
        "from nanshe_workflow.imp import normalize_data_halo\n",
        "from nanshe_workflow.par import halo_block_generate_dictionary_parallel\n",
        "from nanshe_workflow.imp import block_postprocess_data_parallel\n",
        "\n",
        "par_extract_f0 = halo_block_parallel(client, extract_f0_halo)(extract_f0)\n",
        "par_wavelet_transform = halo_block_parallel(client, wavelet_transform_halo)(wavelet_transform)\n",
        "par_normalize_data = halo_block_parallel(client, normalize_data_halo)(normalize_data)\n",
        "par_generate_dictionary = halo_block_generate_dictionary_parallel(client, None)(generate_dictionary)\n",
        "par_postprocess_data = block_postprocess_data_parallel(client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from nanshe_workflow.par import frame_stack_calculate_parallel\n",
        "from nanshe_workflow.par import stack_compute_subtract_parallel\n",
        "\n",
        "from nanshe_workflow.proj import stack_compute_traces_parallel\n",
        "\n",
        "from nanshe_workflow.proj import stack_compute_harmonic_mean_projection_parallel\n",
        "from nanshe_workflow.proj import stack_compute_adj_harmonic_mean_projection_parallel\n",
        "from nanshe_workflow.proj import stack_compute_quantile_projection_parallel\n",
        "from nanshe_workflow.proj import stack_compute_min_projection_parallel\n",
        "from nanshe_workflow.proj import stack_compute_max_projection_parallel\n",
        "\n",
        "from nanshe_workflow.proj import stack_compute_moment_projections_parallel\n",
        "\n",
        "from nanshe_workflow.proj import stack_norm_layer_parallel\n",
        "\n",
        "\n",
        "\n",
        "par_compute_subtract = frame_stack_calculate_parallel(client, stack_compute_subtract_parallel)\n",
        "\n",
        "par_compute_harmonic_mean_projection = frame_stack_calculate_parallel(client, stack_compute_harmonic_mean_projection_parallel)\n",
        "par_compute_adj_harmonic_mean_projection = frame_stack_calculate_parallel(client, stack_compute_adj_harmonic_mean_projection_parallel)\n",
        "\n",
        "par_compute_traces = frame_stack_calculate_parallel(client, stack_compute_traces_parallel)\n",
        "\n",
        "par_compute_quantile_projection = frame_stack_calculate_parallel(client, stack_compute_quantile_projection_parallel)\n",
        "par_compute_min_projection = frame_stack_calculate_parallel(client, stack_compute_min_projection_parallel)\n",
        "par_compute_max_projection = frame_stack_calculate_parallel(client, stack_compute_max_projection_parallel)\n",
        "\n",
        "par_compute_moment_projections = frame_stack_calculate_parallel(client, stack_compute_moment_projections_parallel)\n",
        "\n",
        "par_norm_layer = frame_stack_calculate_parallel(client, stack_norm_layer_parallel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Begin workflow. Set parameters and run each cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View Input Data\n",
        "\n",
        "* `norm_frames` (`int`): number of frames for use during normalization of each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "norm_frames = 100\n",
        "\n",
        "if __IPYTHON__:\n",
        "    result_image_stack = LazyDataset(data, dataset)\n",
        "\n",
        "    mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "    mplsv.set_images(\n",
        "        result_image_stack,\n",
        "        vmin=par_compute_min_projection(num_frames=norm_frames)(result_image_stack).min(),\n",
        "        vmax=par_compute_max_projection(num_frames=norm_frames)(result_image_stack).max()\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Projections\n",
        "\n",
        "* `block_frames` (`int`): number of frames to work with in each block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "block_frames = 100\n",
        "\n",
        "\n",
        "# Somehow we can't overwrite the file in the container so this is needed.\n",
        "if os.path.exists(data_proj):\n",
        "    os.remove(data_proj)\n",
        "\n",
        "images = LazyDataset(data, dataset)\n",
        "with images.astype(numpy.float32) as images:\n",
        "    with h5py.File(data_proj, \"w\") as f:\n",
        "        imgproj_hmean = par_compute_adj_harmonic_mean_projection(num_frames=block_frames)(images)\n",
        "\n",
        "        imgproj_max = par_compute_max_projection(num_frames=block_frames)(images)\n",
        "\n",
        "        imgproj_mean, imgproj_std = par_compute_moment_projections(num_frames=block_frames)(images, 3)[1:]\n",
        "        imgproj_std -= imgproj_mean**2\n",
        "        numpy.sqrt(imgproj_std, out=imgproj_std)\n",
        "\n",
        "        f[\"hmean\"] = imgproj_hmean\n",
        "        f[\"mean\"] = imgproj_mean\n",
        "        f[\"max\"] = imgproj_max\n",
        "        f[\"std\"] = imgproj_std\n",
        "\n",
        "        imgproj_hmean = None\n",
        "        imgproj_mean = None\n",
        "        imgproj_max = None\n",
        "        imgproj_std = None\n",
        "\n",
        "        del imgproj_hmean\n",
        "        del imgproj_mean\n",
        "        del imgproj_max\n",
        "        del imgproj_std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtract Projection\n",
        "\n",
        "* `block_frames` (`int`): number of frames to work with in each block (run in parallel).\n",
        "* `norm_frames` (`int`): number of frames for use during normalization of each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "block_frames = 100\n",
        "norm_frames = 100\n",
        "\n",
        "\n",
        "# Somehow we can't overwrite the file in the container so this is needed.\n",
        "if os.path.exists(data_sub):\n",
        "    os.remove(data_sub)\n",
        "\n",
        "images = LazyDataset(data, dataset)\n",
        "image_back = LazyDataset(data_proj, \"hmean\")\n",
        "with images.astype(numpy.float32) as images:\n",
        "    with h5py.File(data_sub, \"w\") as f2:\n",
        "        result = f2.create_dataset(\"images\", shape=images.shape, dtype=images.dtype, chunks=True)\n",
        "        par_compute_subtract(num_frames=block_frames)(images, image_back, out=result)\n",
        "\n",
        "        result_j = f2.create_dataset(\"images_j\", shape=images.shape, dtype=numpy.uint16, chunks=True)\n",
        "        par_norm_layer(num_frames=norm_frames)(result, out=result_j)\n",
        "\n",
        "\n",
        "if __IPYTHON__:\n",
        "    result_image_stack = LazyDataset(data_sub, \"images\")\n",
        "\n",
        "    mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "    mplsv.set_images(\n",
        "        result_image_stack,\n",
        "        vmin=par_compute_min_projection(num_frames=block_frames)(result_image_stack).min(),\n",
        "        vmax=par_compute_max_projection(num_frames=block_frames)(result_image_stack).max()\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Background Subtraction\n",
        "\n",
        "* `half_window_size` (`int`): the rank filter window size is `2*half_window_size+1`.\n",
        "* `which_quantile` (`float`): which quantile to return from the rank filter.\n",
        "* `temporal_smoothing_gaussian_filter_stdev` (`float`): stdev for gaussian filter to convolve over time.\n",
        "* `temporal_smoothing_gaussian_filter_window_size` (`float`): window for gaussian filter to convolve over time. (Measured in standard deviations)\n",
        "* `spatial_smoothing_gaussian_filter_stdev` (`float`): stdev for gaussian filter to convolve over space.\n",
        "* `spatial_smoothing_gaussian_filter_window_size` (`float`): window for gaussian filter to convolve over space. (Measured in standard deviations)\n",
        "\n",
        "<br>\n",
        "* `block_frames` (`int`): number of frames to work with in each block (run in parallel).\n",
        "* `block_space` (`int`): extent of each spatial dimension for each block (run in parallel).\n",
        "* `norm_frames` (`int`): number of frames for use during normalization of each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "half_window_size = 100\n",
        "which_quantile = 0.5\n",
        "temporal_smoothing_gaussian_filter_stdev = 0.0\n",
        "temporal_smoothing_gaussian_filter_window_size = 0\n",
        "spatial_smoothing_gaussian_filter_stdev = 0.0\n",
        "spatial_smoothing_gaussian_filter_window_size = 0\n",
        "\n",
        "block_frames = 1000\n",
        "block_space = 100\n",
        "norm_frames = 100\n",
        "\n",
        "\n",
        "# Somehow we can't overwrite the file in the container so this is needed.\n",
        "if os.path.exists(data_f_f0):\n",
        "    os.remove(data_f_f0)\n",
        "\n",
        "image_stack = LazyDataset(data_sub, \"images\")\n",
        "block_shape = (block_frames,) + (block_space,) * (len(image_stack.shape) - 1)\n",
        "\n",
        "bias = 1 - par_compute_min_projection(num_frames=norm_frames)(image_stack).min()\n",
        "\n",
        "with h5py.File(data_f_f0, \"w\") as f2:\n",
        "    result = f2.create_dataset(\"images\", shape=image_stack.shape, dtype=image_stack.dtype, chunks=True)\n",
        "\n",
        "    par_extract_f0(block_shape)(\n",
        "        image_stack,\n",
        "        half_window_size=half_window_size,\n",
        "        which_quantile=which_quantile,\n",
        "        temporal_smoothing_gaussian_filter_stdev=temporal_smoothing_gaussian_filter_stdev,\n",
        "        temporal_smoothing_gaussian_filter_window_size=temporal_smoothing_gaussian_filter_window_size,\n",
        "        spatial_smoothing_gaussian_filter_stdev=spatial_smoothing_gaussian_filter_stdev,\n",
        "        spatial_smoothing_gaussian_filter_window_size=spatial_smoothing_gaussian_filter_window_size,\n",
        "        bias=bias,\n",
        "        out=result\n",
        "    )\n",
        "\n",
        "    result_j = f2.create_dataset(\"images_j\", shape=image_stack.shape, dtype=numpy.uint16, chunks=True)\n",
        "    par_norm_layer(num_frames=norm_frames)(result, out=result_j)\n",
        "\n",
        "\n",
        "if __IPYTHON__:\n",
        "    result_image_stack = LazyDataset(data_f_f0, \"images\")\n",
        "\n",
        "    mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "    mplsv.set_images(\n",
        "        result_image_stack,\n",
        "        vmin=par_compute_min_projection(num_frames=norm_frames)(result_image_stack).min(),\n",
        "        vmax=par_compute_max_projection(num_frames=norm_frames)(result_image_stack).max()\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wavelet Transform\n",
        "\n",
        "* `scale` (`int`): the scale of wavelet transform to apply.\n",
        "\n",
        "<br>\n",
        "* `block_frames` (`int`): number of frames to work with in each block (run in parallel).\n",
        "* `block_space` (`int`): extent of each spatial dimension for each block (run in parallel).\n",
        "* `norm_frames` (`int`): number of frames for use during normalization of each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "scale = 3\n",
        "\n",
        "block_frames = 250\n",
        "block_space = 250\n",
        "norm_frames = 100\n",
        "\n",
        "\n",
        "# Somehow we can't overwrite the file in the container so this is needed.\n",
        "if os.path.exists(data_wt):\n",
        "    os.remove(data_wt)\n",
        "\n",
        "result = LazyDataset(data_f_f0, \"images\")\n",
        "block_shape = (block_frames,) + (block_space,) * (len(result.shape) - 1)\n",
        "with h5py.File(data_wt, \"w\") as f2:\n",
        "    new_result = f2.create_dataset(\"images\", shape=result.shape, dtype=result.dtype, chunks=True)\n",
        "\n",
        "    par_wavelet_transform(block_shape)(\n",
        "        result,\n",
        "        scale=scale,\n",
        "        out=new_result\n",
        "    )\n",
        "\n",
        "    result_j = f2.create_dataset(\"images_j\", shape=new_result.shape, dtype=numpy.uint16, chunks=True)\n",
        "    par_norm_layer(num_frames=norm_frames)(result, out=result_j)\n",
        "\n",
        "\n",
        "if __IPYTHON__:\n",
        "    result_image_stack = LazyDataset(data_wt, \"images\")\n",
        "\n",
        "    mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "    mplsv.set_images(\n",
        "        result_image_stack,\n",
        "        vmin=par_compute_min_projection(num_frames=norm_frames)(result_image_stack).min(),\n",
        "        vmax=par_compute_max_projection(num_frames=norm_frames)(result_image_stack).max()\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalize Data\n",
        "* `block_frames` (`int`): number of frames to work with in each full frame block (run in parallel).\n",
        "* `norm_frames` (`int`): number of frames for use during normalization of each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "block_frames = 40\n",
        "norm_frames = 100\n",
        "\n",
        "\n",
        "# Somehow we can't overwrite the file in the container so this is needed.\n",
        "if os.path.exists(data_norm):\n",
        "    os.remove(data_norm)\n",
        "\n",
        "result = LazyDataset(data_wt, \"images\")\n",
        "block_shape = (block_frames,) + result.shape[1:]\n",
        "with h5py.File(data_norm, \"w\") as f2:\n",
        "    new_result = f2.create_dataset(\"images\", shape=result.shape, dtype=result.dtype, chunks=True)\n",
        "\n",
        "    result = par_normalize_data(block_shape)(\n",
        "        result,\n",
        "        out=new_result\n",
        "    )\n",
        "\n",
        "    result_j = f2.create_dataset(\"images_j\", shape=new_result.shape, dtype=numpy.uint16, chunks=True)\n",
        "    par_norm_layer(num_frames=norm_frames)(result, out=result_j)\n",
        "\n",
        "\n",
        "if __IPYTHON__:\n",
        "    result_image_stack = LazyDataset(data_norm, \"images\")\n",
        "\n",
        "    mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "    mplsv.set_images(\n",
        "        result_image_stack,\n",
        "        vmin=par_compute_min_projection(num_frames=norm_frames)(result_image_stack).min(),\n",
        "        vmax=par_compute_max_projection(num_frames=norm_frames)(result_image_stack).max()\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dictionary Learning\n",
        "\n",
        "* `n_components` (`int`): number of basis images in the dictionary.\n",
        "* `batchsize` (`int`): minibatch size to use.\n",
        "* `iters` (`int`): number of iterations to run before getting dictionary.\n",
        "* `lambda1` (`float`): weight for L<sup>1</sup> sparisty enforcement on sparse code.\n",
        "* `lambda2` (`float`): weight for L<sup>2</sup> sparisty enforcement on sparse code.\n",
        "\n",
        "<br>\n",
        "* `block_frames` (`int`): number of frames to work with in each full frame block (run in parallel).\n",
        "* `norm_frames` (`int`): number of frames for use during normalization of each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "n_components = 50\n",
        "batchsize = 256\n",
        "iters = 100\n",
        "lambda1 = 0.2\n",
        "lambda2 = 0.0\n",
        "\n",
        "block_frames = 51\n",
        "norm_frames = 100\n",
        "\n",
        "\n",
        "# Somehow we can't overwrite the file in the container so this is needed.\n",
        "if os.path.exists(data_dict):\n",
        "    os.remove(data_dict)\n",
        "\n",
        "result = LazyDataset(data_norm, \"images\")\n",
        "block_shape = (block_frames,) + result.shape[1:]\n",
        "with h5py.File(data_dict, \"w\") as f2:\n",
        "    new_result = f2.create_dataset(\"images\", shape=(n_components,) + result.shape[1:], dtype=result.dtype, chunks=True)\n",
        "\n",
        "    result = par_generate_dictionary(block_shape)(\n",
        "        result,\n",
        "        n_components=n_components,\n",
        "        out=new_result,\n",
        "        **{\"sklearn.decomposition.dict_learning_online\" : {\n",
        "                \"n_jobs\" : 1,\n",
        "                \"n_iter\" : iters,\n",
        "                \"batch_size\" : batchsize,\n",
        "                \"alpha\" : lambda1\n",
        "            }\n",
        "        }\n",
        "    )\n",
        "\n",
        "    result_j = f2.create_dataset(\"images_j\", shape=new_result.shape, dtype=numpy.uint16, chunks=True)\n",
        "    par_norm_layer(num_frames=norm_frames)(result, out=result_j)\n",
        "\n",
        "\n",
        "if __IPYTHON__:\n",
        "    result_image_stack = LazyDataset(data_dict, \"images\")\n",
        "\n",
        "    mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "    mplsv.set_images(\n",
        "        result_image_stack,\n",
        "        vmin=par_compute_min_projection(num_frames=norm_frames)(result_image_stack).min(),\n",
        "        vmax=par_compute_max_projection(num_frames=norm_frames)(result_image_stack).max()\n",
        "    )\n",
        "    mplsv.time_nav.stime.label.set_text(\"Basis Image\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Postprocessing\n",
        "\n",
        "* `significance_threshold` (`float`): number of standard deviations below which to include in \"noise\" estimate\n",
        "* `wavelet_scale` (`int`): scale of wavelet transform to apply (should be the same as the one used above)\n",
        "* `noise_threshold` (`float`): number of units of \"noise\" above which something needs to be to be significant\n",
        "* `accepted_region_shape_constraints` (`dict`): if ROIs don't match this, reduce the `wavelet_scale` once.\n",
        "* `percentage_pixels_below_max` (`float`): upper bound on ratio of ROI pixels not at max intensity vs. all ROI pixels\n",
        "* `min_local_max_distance` (`float`): minimum allowable euclidean distance between two ROIs maximum intensities\n",
        "* `accepted_neuron_shape_constraints` (`dict`): shape constraints for ROI to be kept.\n",
        "\n",
        "* `alignment_min_threshold` (`float`): similarity measure of the intensity of two ROIs images used for merging.\n",
        "* `overlap_min_threshold` (`float`): similarity measure of the masks of two ROIs used for merging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "significance_threshold = 3.0\n",
        "wavelet_scale = 3\n",
        "noise_threshold = 2.0\n",
        "percentage_pixels_below_max = 0.8\n",
        "min_local_max_distance = 16.0\n",
        "\n",
        "alignment_min_threshold = 0.6\n",
        "overlap_min_threshold = 0.6\n",
        "\n",
        "\n",
        "# Somehow we can't overwrite the file in the container so this is needed.\n",
        "if os.path.exists(data_post):\n",
        "    os.remove(data_post)\n",
        "\n",
        "result = LazyDataset(data_dict, \"images\")\n",
        "with h5py.File(data_post, \"w\") as f2:\n",
        "    result = par_postprocess_data(result,\n",
        "                                  **{\n",
        "                                        \"wavelet_denoising\" : {\n",
        "                                            \"estimate_noise\" : {\n",
        "                                                \"significance_threshold\" : significance_threshold\n",
        "                                            },\n",
        "                                            \"wavelet.transform\" : {\n",
        "                                                \"scale\" : wavelet_scale\n",
        "                                            },\n",
        "                                            \"significant_mask\" : {\n",
        "                                                \"noise_threshold\" : noise_threshold\n",
        "                                            },\n",
        "                                            \"accepted_region_shape_constraints\" : {\n",
        "                                                \"major_axis_length\" : {\n",
        "                                                    \"min\" : 0.0,\n",
        "                                                    \"max\" : 25.0\n",
        "                                                }\n",
        "                                            },\n",
        "                                            \"remove_low_intensity_local_maxima\" : {\n",
        "                                                \"percentage_pixels_below_max\" : percentage_pixels_below_max\n",
        "                                            },\n",
        "                                            \"remove_too_close_local_maxima\" : {\n",
        "                                                \"min_local_max_distance\" : min_local_max_distance\n",
        "                                            },\n",
        "                                            \"accepted_neuron_shape_constraints\" : {\n",
        "                                                \"area\" : {\n",
        "                                                    \"min\" : 25,\n",
        "                                                    \"max\" : 600\n",
        "                                                },\n",
        "                                                \"eccentricity\" : {\n",
        "                                                    \"min\" : 0.0,\n",
        "                                                    \"max\" : 0.9\n",
        "                                                }\n",
        "                                            }\n",
        "                                        },\n",
        "                                        \"merge_neuron_sets\" : {\n",
        "                                            \"alignment_min_threshold\" : alignment_min_threshold,\n",
        "                                            \"overlap_min_threshold\" : overlap_min_threshold,\n",
        "                                            \"fuse_neurons\" : {\n",
        "                                                \"fraction_mean_neuron_max_threshold\" : 0.01\n",
        "                                            }\n",
        "                                        }\n",
        "                                  }\n",
        "    )\n",
        "\n",
        "    result = f2.create_dataset(\"rois\", shape=result.shape, dtype=result.dtype, data=result, chunks=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROI and trace extraction\n",
        "\n",
        "* `block_frames` (`int`): number of frames to work with in each block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "block_frames = 100\n",
        "\n",
        "\n",
        "# Somehow we can't overwrite the file in the container so this is needed.\n",
        "if os.path.exists(data_rois):\n",
        "    os.remove(data_rois)\n",
        "\n",
        "with h5py.File(data_rois, \"w\") as f2:\n",
        "    with h5py.File(data_post, \"r\") as f1:\n",
        "        f2.create_dataset(\n",
        "            \"masks\",\n",
        "            shape=f1[\"rois\"].shape + f1[\"rois\"].dtype[\"mask\"].shape,\n",
        "            dtype=f1[\"rois\"].dtype[\"mask\"].subdtype[0],\n",
        "            chunks=True\n",
        "        )\n",
        "        for i, j in sliding_window(2, range(0, len(f1[\"rois\"]) + block_frames, block_frames)):\n",
        "            f2[\"masks\"][i:j] = f1[\"rois\"][i:j, \"mask\"]\n",
        "\n",
        "    mskimg = f2[\"masks\"]\n",
        "    mskimg_j = f2.create_dataset(\"masks_j\", shape=mskimg.shape, dtype=numpy.uint8, chunks=True)\n",
        "    par_norm_layer(num_frames=block_frames)(mskimg, out=mskimg_j)\n",
        "\n",
        "    lblimg = label_mask_stack(mskimg, np.uint64)\n",
        "    f2[\"labels\"] = lblimg\n",
        "    f2[\"labels_j\"] = lblimg.astype(np.uint16)\n",
        "    lblimg = f2[\"labels\"]\n",
        "\n",
        "# Somehow we can't overwrite the file in the container so this is needed.\n",
        "if os.path.exists(data_traces):\n",
        "    os.remove(data_traces)\n",
        "\n",
        "images = LazyDataset(data_f_f0, \"images\")\n",
        "mskimg = LazyDataset(data_rois, \"masks\")\n",
        "with h5py.File(data_traces, \"w\") as f2:\n",
        "    traces = f2.create_dataset(\"traces\", shape=(len(mskimg), len(images)), dtype=images.dtype, chunks=True)\n",
        "    par_compute_traces(num_frames=block_frames)(images, mskimg, out=traces)\n",
        "    traces_j = f2.create_dataset(\"traces_j\", shape=traces.shape, dtype=numpy.uint16, chunks=True)\n",
        "    par_norm_layer(num_frames=block_frames)(traces, out=traces_j)\n",
        "\n",
        "\n",
        "if __IPYTHON__:\n",
        "    result_image_stack = LazyDataset(data_f_f0, \"images\")\n",
        "    lblimg = LazyDataset(data_rois, \"labels\")\n",
        "\n",
        "    mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "    mplsv.set_images(\n",
        "        result_image_stack,\n",
        "        vmin=par_compute_min_projection(num_frames=block_frames)(result_image_stack).min(),\n",
        "        vmax=par_compute_max_projection(num_frames=block_frames)(result_image_stack).max()\n",
        "    )\n",
        "\n",
        "    lblimg_msk = numpy.ma.masked_array(lblimg[...][...], mask=(lblimg==0))\n",
        "\n",
        "    mplsv.viewer.matshow(lblimg_msk, alpha=0.3)\n",
        "\n",
        "\n",
        "mskimg = None\n",
        "mskimg_j = None\n",
        "lblimg = None\n",
        "traces = None\n",
        "traces_j = None\n",
        "\n",
        "del mskimg\n",
        "del mskimg_j\n",
        "del lblimg\n",
        "del traces\n",
        "del traces_j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End of workflow. Shutdown cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nanshe_workflow.par import cleanup_cluster_files\n",
        "\n",
        "from sys import executable as PYTHON\n",
        "!$PYTHON -m ipyparallel.apps.ipclusterapp stop --profile=sge\n",
        "del PYTHON\n",
        "\n",
        "cleanup_cluster_files(\"sge\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare interactive projection graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import textwrap\n",
        "\n",
        "import numpy\n",
        "import numpy as np\n",
        "\n",
        "import scipy\n",
        "import scipy as sp\n",
        "\n",
        "import scipy.ndimage\n",
        "import scipy.ndimage as spim\n",
        "\n",
        "import h5py\n",
        "import h5py as hp\n",
        "\n",
        "import bokeh.plotting\n",
        "import bokeh.plotting as bp\n",
        "\n",
        "import bokeh.io\n",
        "import bokeh.io as bio\n",
        "\n",
        "import bokeh.embed\n",
        "import bokeh.embed as be\n",
        "\n",
        "from bokeh.models.mappers import LinearColorMapper\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.cm\n",
        "\n",
        "from matplotlib.colors import ColorConverter\n",
        "from matplotlib.cm import gist_rainbow\n",
        "\n",
        "import webcolors\n",
        "\n",
        "from bokeh.models import CustomJS, ColumnDataSource, HoverTool\n",
        "from bokeh.models.layouts import HBox\n",
        "\n",
        "from builtins import (\n",
        "    map as imap,\n",
        "    range as irange\n",
        ")\n",
        "\n",
        "from past.builtins import basestring\n",
        "\n",
        "import nanshe\n",
        "\n",
        "import xnumpy\n",
        "import xnumpy.core\n",
        "from xnumpy.core import expand\n",
        "\n",
        "import nanshe_workflow\n",
        "from nanshe_workflow.vis import get_rgb_array, get_rgba_array, get_all_greys, masks_to_contours_2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with h5py.File(data_rois, \"r\") as f:\n",
        "    mskimg = f[\"masks\"][...]\n",
        "\n",
        "with h5py.File(data_traces, \"r\") as f:\n",
        "    traces = f[\"traces\"][...]\n",
        "\n",
        "with h5py.File(data_proj, \"r\") as f:\n",
        "    imgproj_mean = f[\"mean\"][...]\n",
        "    imgproj_max = f[\"max\"][...]\n",
        "    imgproj_std = f[\"std\"][...]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result visualization\n",
        "* `proj_img` (`str` or `list` of `str`): which projection or projections to plot (e.g. \"max\", \"mean\", \"std\").\n",
        "* `block_size` (`int`): size of each point on any dimension in the image in terms of pixels.\n",
        "* `roi_alpha` (`float`): transparency of the ROIs in a range of [0.0, 1.0].\n",
        "* `roi_border_width` (`int`): width of the line border on each ROI.\n",
        "\n",
        "<br>\n",
        "* `trace_plot_width` (`int`): width of the trace plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "proj_img = \"std\"\n",
        "block_size = 1\n",
        "roi_alpha = 0.3\n",
        "roi_border_width = 3\n",
        "trace_plot_width = 500\n",
        "\n",
        "\n",
        "bio.curdoc().clear()\n",
        "\n",
        "grey_range = get_all_greys()\n",
        "grey_cm = LinearColorMapper(grey_range)\n",
        "\n",
        "colors_rgb = get_rgb_array(len(mskimg))\n",
        "colors_rgb = colors_rgb.tolist()\n",
        "colors_rgb = list(imap(webcolors.rgb_to_hex, colors_rgb))\n",
        "\n",
        "mskctr_pts_y, mskctr_pts_x = masks_to_contours_2d(mskimg)\n",
        "\n",
        "mskctr_pts_dtype = np.min_scalar_type(max(mskimg.shape[1:]) - 1)\n",
        "mskctr_pts_y = [np.array(_, dtype=mskctr_pts_dtype) for _ in mskctr_pts_y]\n",
        "mskctr_pts_x = [np.array(_, dtype=mskctr_pts_dtype) for _ in mskctr_pts_x]\n",
        "\n",
        "mskctr_srcs = ColumnDataSource(data=dict(x=mskctr_pts_x, y=mskctr_pts_y, color=colors_rgb))\n",
        "\n",
        "\n",
        "if isinstance(proj_img, basestring):\n",
        "    proj_img = [proj_img]\n",
        "else:\n",
        "    proj_img = list(proj_img)\n",
        "\n",
        "\n",
        "proj_plot_width = block_size*mskimg.shape[2]\n",
        "proj_plot_height = block_size*mskimg.shape[1]\n",
        "plot_projs = []\n",
        "\n",
        "if \"max\" in proj_img:\n",
        "    plot_max = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"resize\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Max Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_max.image(image=[numpy.flipud(imgproj_max)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[imgproj_max.shape[1]], dh=[imgproj_max.shape[0]], color_mapper=grey_cm)\n",
        "    plot_max.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_max.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_max.axis)):\n",
        "        plot_max.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_max)\n",
        "\n",
        "\n",
        "if \"mean\" in proj_img:\n",
        "    plot_mean = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"resize\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Mean Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_mean.image(image=[numpy.flipud(imgproj_mean)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[mskimg.shape[2]], dh=[mskimg.shape[1]], color_mapper=grey_cm)\n",
        "    plot_mean.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_mean.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_mean.axis)):\n",
        "        plot_mean.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_mean)\n",
        "\n",
        "\n",
        "if \"std\" in proj_img:\n",
        "    plot_std = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"resize\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Std Dev Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_std.image(image=[numpy.flipud(imgproj_std)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[mskimg.shape[2]], dh=[mskimg.shape[1]], color_mapper=grey_cm)\n",
        "    plot_std.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_std.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_std.axis)):\n",
        "        plot_std.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_std)\n",
        "\n",
        "\n",
        "all_tr_shape_srcs = ColumnDataSource(data=dict(traces_shape=traces.shape))\n",
        "all_tr_srcs = ColumnDataSource(data=dict(traces=traces.flatten()))\n",
        "tr_srcs = ColumnDataSource(data=dict(times_sel=[], traces_sel=[], colors_sel=[]))\n",
        "plot_tr = bp.Figure(plot_width=trace_plot_width, plot_height=proj_plot_height,\n",
        "                    x_range=(0.0, float(traces.shape[1])), y_range=(float(traces.min()), float(traces.max())),\n",
        "                    tools=[\"pan\", \"box_zoom\", \"resize\", \"wheel_zoom\", \"save\", \"reset\"], title=\"ROI traces\",\n",
        "                    background_fill_color=\"black\", border_fill_color=\"black\")\n",
        "plot_tr.multi_line(\"times_sel\", \"traces_sel\", source=tr_srcs, color=\"colors_sel\")\n",
        "\n",
        "plot_tr.outline_line_color = \"white\"\n",
        "for i in irange(len(plot_tr.axis)):\n",
        "    plot_tr.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "plot_projs.append(plot_tr)\n",
        "\n",
        "\n",
        "mskctr_srcs.callback = CustomJS(\n",
        "    args=dict(\n",
        "        all_tr_shape_srcs=all_tr_shape_srcs,\n",
        "        all_tr_srcs=all_tr_srcs,\n",
        "        tr_srcs=tr_srcs\n",
        "    ), code=\"\"\"\n",
        "    var range = function(n){ return Array.from(Array(n).keys()); };\n",
        "\n",
        "    var inds = cb_obj.get('selected')['1d'].indices;\n",
        "    var traces = all_tr_srcs.get('data')['traces'];\n",
        "    var traces_shape = all_tr_shape_srcs.get('data')['traces_shape'];\n",
        "    var trace_len = traces_shape[1];\n",
        "    var colors = cb_obj.get('data')['color'];\n",
        "    var selected = tr_srcs.get('data');\n",
        "\n",
        "    var times = range(trace_len);\n",
        "\n",
        "    selected['times_sel'] = [];\n",
        "    selected['traces_sel'] = [];\n",
        "    selected['colors_sel'] = [];\n",
        "\n",
        "    for (i = 0; i < inds.length; i++) {\n",
        "        var inds_i = inds[i];\n",
        "        var trace_i = traces.slice(trace_len*inds_i, trace_len*(inds_i+1));\n",
        "        var color_i = colors[inds_i];\n",
        "\n",
        "        selected['times_sel'].push(times);\n",
        "        selected['traces_sel'].push(trace_i);\n",
        "        selected['colors_sel'].push(color_i);\n",
        "    }\n",
        "\n",
        "    tr_srcs.trigger('change');\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "plot_group = HBox(*plot_projs)\n",
        "\n",
        "\n",
        "# Clear out the old HTML file before writing a new one.\n",
        "if os.path.exists(data_proj_html):\n",
        "    os.remove(data_proj_html)\n",
        "\n",
        "\n",
        "def indent(text, spaces):\n",
        "    spaces = \" \" * int(spaces)\n",
        "    return \"\\n\".join(imap(lambda l: spaces + l, text.splitlines()))\n",
        "\n",
        "def write_html(filename, title, div, script):\n",
        "    indent(bokeh.resources.CDN.render(), 8)\n",
        "    html_tmplt = textwrap.dedent(u\"\"\"\\\n",
        "        <html lang=\"en\">\n",
        "            <head>\n",
        "                <meta charset=\"utf-8\">\n",
        "                <title>{title}</title>\n",
        "                {cdn}\n",
        "                <style>\n",
        "                  html {{\n",
        "                    width: 100%;\n",
        "                    height: 100%;\n",
        "                  }}\n",
        "                  body {{\n",
        "                    width: 90%;\n",
        "                    height: 100%;\n",
        "                    margin: auto;\n",
        "                    background-color: black;\n",
        "                  }}\n",
        "                </style>\n",
        "            </head>\n",
        "            <body>\n",
        "                {div}\n",
        "                {script}\n",
        "            </body>\n",
        "        </html>\n",
        "    \"\"\")\n",
        "\n",
        "    html_cont = html_tmplt.format(\n",
        "        title=title,\n",
        "        div=indent(div, 8),\n",
        "        script=indent(script, 8),\n",
        "        cdn=indent(bokeh.resources.CDN.render(), 8),\n",
        "    )\n",
        "\n",
        "    with io.open(filename, \"w\") as fh:\n",
        "        fh.write(html_cont)\n",
        "\n",
        "script, div = be.components(plot_group)\n",
        "write_html(data_proj_html, os.path.splitext(data_proj_html)[0], div, script)\n",
        "\n",
        "\n",
        "if __IPYTHON__:\n",
        "    from IPython.display import display, IFrame\n",
        "    display(IFrame(data_proj_html, \"100%\", 1.05*proj_plot_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Test teardown. Ignore warnings during production runs.\n",
        "\n",
        "%run ./teardown_tests.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "widgets": {
      "state": {},
      "version": "1.2.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
